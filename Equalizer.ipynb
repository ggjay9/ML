{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from zipfile import ZipFile\n",
        "import re\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "P5hUIFCdi-o6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41378212-46a7-41b7-df1d-d6ccaf1ec79b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data\n",
        "\n",
        "!wget -O x.zip \"https://drive.google.com/uc?export=download&id=1221858Ognjuffo3Pv6QezSiBw8xBOBe-\"\n",
        "\n",
        "with ZipFile('/content/x.zip', 'r') as f:\n",
        "  f.extract('x.txt')\n",
        "\n",
        "x_real = []\n",
        "x_imag = []\n",
        "x = []\n",
        "#with open('drive/MyDrive/x.txt') as input_file:\n",
        "with open('x.txt') as input_file:\n",
        "    for line in input_file:\n",
        "      temp = re.sub(r'[()]', \"\", line)\n",
        "      temp = complex(temp)\n",
        "      x.append((temp.real, temp.imag))\n",
        "      x_real.append(temp.real)\n",
        "      x_imag.append(temp.imag)\n",
        "\n",
        "y_real = []\n",
        "y_imag = []\n",
        "#with open('drive/MyDrive/y.txt') as input_file:\n",
        "with open('y.txt') as input_file:\n",
        "    for line in input_file:\n",
        "      temp = re.sub(r'[()]', \"\", line)\n",
        "      temp = complex(temp)\n",
        "      y_real.append(temp.real)\n",
        "      y_imag.append(temp.imag)"
      ],
      "metadata": {
        "id": "TrV0uidojeej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conversion to TensorFlow\n",
        "\n",
        "x_real_t = torch.Tensor(x_real).reshape(-1,1)\n",
        "x_imag_t = torch.Tensor(x_imag).reshape(-1,1)\n",
        "X = torch.stack((x_real_t, x_imag_t), -1)\n",
        "\n",
        "y_real_t = torch.Tensor(y_real).reshape(-1,1)\n",
        "y_imag_t = torch.Tensor(y_imag).reshape(-1,1)\n",
        "Y = torch.stack((y_real_t, y_imag_t), -1)"
      ],
      "metadata": {
        "id": "YtRh7k3QjYZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide your data into training, validation and test dataset\n",
        "\n",
        "x_train, x_test =  train_test_split(X, test_size=0.2, shuffle=False)\n",
        "y_train, y_test =  train_test_split(Y, test_size=0.2, shuffle=False)\n",
        "\n",
        "x_val, x_test =  train_test_split(X, test_size=0.5, shuffle=False)\n",
        "y_val, y_test =  train_test_split(Y, test_size=0.5, shuffle=False)"
      ],
      "metadata": {
        "id": "NgWgR0MejTYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define nonlinear NN for equalizer\n",
        "\n",
        "class NonlinEq(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lin1 = nn.Linear(2, 50)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.lin2 = nn.Linear(50, 20)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.lin3 = nn.Linear(20,2)\n",
        "\n",
        "    def forward(self, y):\n",
        "        y = self.relu1(self.lin1(y))\n",
        "        y = self.relu2(self.lin2(y))\n",
        "        return self.lin3(y)[::2]"
      ],
      "metadata": {
        "id": "lNnDdjccjQEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "lr = 1e-2  # learning rate\n",
        "num_epochs = 101"
      ],
      "metadata": {
        "id": "2E-0TiJzjMdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize NN\n",
        "\n",
        "torch.manual_seed(5)  \n",
        "nleq = NonlinEq()\n",
        "optimizer = optim.Adam(nleq.parameters(), lr=lr)\n",
        "\n",
        "loss_last_batch = []\n",
        "loss_val_set = []"
      ],
      "metadata": {
        "id": "uPmG-qF2jH_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainings loop\n",
        "\n",
        "for j in range(num_epochs):\n",
        "    y_eq = nleq(Y)\n",
        "    loss = loss_fn(y_eq, X)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # store loss of the last batch \n",
        "    loss_last_batch.append(loss.detach().numpy())\n",
        "    # store loss of validation set \n",
        "    loss_val = loss_fn(nleq(y_val), x_val)\n",
        "    loss_val_set.append(loss_val.detach().numpy())\n",
        "\n",
        "    if j % 10 == 0:\n",
        "        print(f'epoch {j}: Loss = {loss.detach().numpy() :.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mt0KGaJwLZai",
        "outputId": "fbb1d637-a47e-4ea0-94db-5fc200d43f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0: Loss = 0.5115\n",
            "epoch 10: Loss = 0.0752\n",
            "epoch 20: Loss = 0.0364\n",
            "epoch 30: Loss = 0.0259\n",
            "epoch 40: Loss = 0.0209\n",
            "epoch 50: Loss = 0.0176\n",
            "epoch 60: Loss = 0.0156\n",
            "epoch 70: Loss = 0.0146\n",
            "epoch 80: Loss = 0.0138\n",
            "epoch 90: Loss = 0.0130\n",
            "epoch 100: Loss = 0.0124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBeHgUBTNPQo"
      },
      "outputs": [],
      "source": [
        "# Save result of the NN\n",
        "\n",
        "torch.save(loss_last_batch, 'last_batch.pt')\n",
        "torch.save(loss_val_set, 'val.pt')\n",
        "torch.save(nleq, 'equal.pth')"
      ]
    }
  ]
}