{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyWu7PfdIzr-",
        "outputId": "702fb08f-3755-4fd5-ae80-f013efb0b35d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByOuK7EnJICd",
        "outputId": "b5c7b171-1da4-41b8-ad3e-ebfb2895b8fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-25 10:33:04--  https://drive.google.com/uc?export=download&id=1u5TAN-nRjHoAQ02J5-3o3Yr53m66Vw56\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.69.139, 74.125.69.101, 74.125.69.138, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.69.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-14-80-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/7i3i3a37kdrcp8ndukccfg947gnnt0oe/1674642750000/00806258749903615801/*/1u5TAN-nRjHoAQ02J5-3o3Yr53m66Vw56?e=download&uuid=96cb40a4-baa3-4114-b0d4-0da1e6d2e0ce [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-01-25 10:33:06--  https://doc-14-80-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/7i3i3a37kdrcp8ndukccfg947gnnt0oe/1674642750000/00806258749903615801/*/1u5TAN-nRjHoAQ02J5-3o3Yr53m66Vw56?e=download&uuid=96cb40a4-baa3-4114-b0d4-0da1e6d2e0ce\n",
            "Resolving doc-14-80-docs.googleusercontent.com (doc-14-80-docs.googleusercontent.com)... 74.125.132.132, 2607:f8b0:4001:c00::84\n",
            "Connecting to doc-14-80-docs.googleusercontent.com (doc-14-80-docs.googleusercontent.com)|74.125.132.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 52000000 (50M) [text/plain]\n",
            "Saving to: ‘a.txt’\n",
            "\n",
            "a.txt               100%[===================>]  49.59M   197MB/s    in 0.3s    \n",
            "\n",
            "2023-01-25 10:33:07 (197 MB/s) - ‘a.txt’ saved [52000000/52000000]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import data\n",
        "\n",
        "!wget -O a.txt \"https://drive.google.com/uc?export=download&id=1u5TAN-nRjHoAQ02J5-3o3Yr53m66Vw56\"\n",
        "\n",
        "a = np.loadtxt('a.txt')\n",
        "a_t = torch.tensor(a)\n",
        "a_t = a_t.type(torch.LongTensor)\n",
        "\n",
        "y_real = []\n",
        "y_imag = []\n",
        "#with open('drive/MyDrive/y.txt') as input_file:\n",
        "with open('y.txt') as input_file:\n",
        "    for line in input_file:\n",
        "      temp = re.sub(r'[()]', \"\", line)\n",
        "      temp = complex(temp)\n",
        "      y_real.append(temp.real)\n",
        "      y_imag.append(temp.imag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26veNgbEJMyh"
      },
      "outputs": [],
      "source": [
        "# Conversion to TensorFlow\n",
        "\n",
        "y_real_t = torch.Tensor(y_real).reshape(-1,1)\n",
        "y_imag_t = torch.Tensor(y_imag).reshape(-1,1)\n",
        "Y = torch.stack((y_real_t, y_imag_t), -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIVooafbJQdM"
      },
      "outputs": [],
      "source": [
        "# Divide your data into training, validation and test dataset\n",
        "\n",
        "a_train, a_test =  train_test_split(a_t, test_size=0.2, shuffle=False)\n",
        "y_train, y_test =  train_test_split(Y, test_size=0.2, shuffle=False)\n",
        "\n",
        "a_val, a_test =  train_test_split(a_t, test_size=0.5, shuffle=False)\n",
        "y_val, y_test =  train_test_split(Y, test_size=0.5, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5OTxnEqLCF0"
      },
      "outputs": [],
      "source": [
        "# Define nonlinear NN for equalizer\n",
        "\n",
        "class NonlinEq(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lin1 = nn.Linear(2, 50)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.lin2 = nn.Linear(50, 20)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.lin3 = nn.Linear(20, 2)\n",
        "\n",
        "    def forward(self, y):\n",
        "        y = self.relu1(self.lin1(y))\n",
        "        y = self.relu2(self.lin2(y))\n",
        "        return self.lin3(y)[::2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Eh2HReId85D"
      },
      "outputs": [],
      "source": [
        "# Define linear NN for Demapping\n",
        "\n",
        "class Demapper(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.out = nn.Linear(2, 16)\n",
        "\n",
        "    def forward(self, y):\n",
        "        return self.out(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nu7NVHH-JYFn"
      },
      "outputs": [],
      "source": [
        "# Define loss function\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "lr = 0.05  # learning rate\n",
        "num_epochs = 151"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuVEfh0lJeJg"
      },
      "outputs": [],
      "source": [
        "# Initialize NN\n",
        "\n",
        "torch.manual_seed(5)  \n",
        "nleq = NonlinEq()\n",
        "demap = Demapper()\n",
        "optimizer = optim.Adam(list(nleq.parameters()) + list(demap.parameters()), lr=lr)\n",
        "\n",
        "loss_last_batch = []\n",
        "loss_val_set = []"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainings loop\n",
        "\n",
        "for j in range(num_epochs):\n",
        "    y_eq = nleq(Y)\n",
        "    logit = demap(y_eq).reshape(-1, 16)\n",
        "    loss = loss_fn(logit, a_t)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # store loss of the last batch \n",
        "    loss_last_batch.append(loss.detach().numpy())\n",
        "    # store loss of validation set \n",
        "    loss_val = loss_fn(demap(nleq(y_val)).reshape(-1, 16), a_val)\n",
        "    loss_val_set.append(loss_val.detach().numpy())\n",
        "\n",
        "    if j % 25 == 0:\n",
        "        print(f'epoch {j}: Loss = {loss.detach().numpy() :.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6kXFHN9ZC2z",
        "outputId": "08ab3201-60f3-4838-a15d-e4156372d947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0: Loss = 2.8066\n",
            "epoch 25: Loss = 0.6975\n",
            "epoch 50: Loss = 0.3503\n",
            "epoch 75: Loss = 0.2189\n",
            "epoch 100: Loss = 0.1556\n",
            "epoch 125: Loss = 0.1241\n",
            "epoch 150: Loss = 0.1061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEqvvRNlJjut"
      },
      "outputs": [],
      "source": [
        "# Save result of the NN\n",
        "\n",
        "torch.save(loss_last_batch, 'last_batch1.pt')\n",
        "torch.save(loss_val_set, 'val1.pt')\n",
        "torch.save(nleq, 'equal1.pth')\n",
        "torch.save(demap, 'demap.pth')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}